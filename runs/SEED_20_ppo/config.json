{
  "ALGO": "PPO",
  "EPISODES": 1000,
  "GAMMA": 0.99,
  "LR_ACTOR": 0.0003,
  "LR_CRITIC": 0.0002,
  "EPSILON_CLIP": 0.18,
  "UPDATE_EPOCHS": 10,
  "BATCH_SIZE": 64,
  "MAX_STEPS": 300,
  "LAMBDA": 0.95,
  "ENTROPY_COEFF": 0.08,
  "REWARD_SCALE": 50.0,
  "GRAD_NORM_CLIP": 0.5,
  "MINIBATCH_MIN": 16,
  "VALUE_CLIP": 0.2,
  "ENTROPY_FLOOR": 0.01,
  "ENTROPY_BOOST": 0.02,
  "BOOST_INTERVAL": 20,
  "LR_DECAY": 0.98
}